{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=pool_size, stride=pool_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x shape \", x.shape)\n",
    "        return self.pool(x)\n",
    "\n",
    "\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, R_scale):\n",
    "        super(Noise, self).__init__()\n",
    "        self.mean = 0\n",
    "        self.stdev = 1  # as defined in the paper\n",
    "\n",
    "    def forward(self, d_coarse):\n",
    "        noise = torch.rand_like(d_coarse)*self.stdev + self.mean\n",
    "        d_noised = d_coarse + noise\n",
    "        return d_noised\n",
    "\n",
    "\n",
    "class IntervalThreshold(nn.Module):\n",
    "    def __init__(self, m, n):\n",
    "        super(IntervalThreshold, self).__init__()\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "\n",
    "    def forward(self, d_pool):\n",
    "        threshold = (torch.max(d_pool) - torch.min(d_pool))/min(self.m, self.n)\n",
    "        return threshold\n",
    "\n",
    "\n",
    "class ReconGraph(nn.Module):\n",
    "    def __init__(self, m, n):\n",
    "        super(ReconGraph, self).__init__()\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "\n",
    "    def forward(self, d_noised, threshold):\n",
    "        neighbours = set()\n",
    "        labels = {}\n",
    "\n",
    "        count = 0\n",
    "        # print(self.m, self.n)\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "\n",
    "                labels[(j, i)] = count  # Labeling each pixel in (x, y) form\n",
    "                count += 1\n",
    "                for dy in range(-1, 2):\n",
    "                    for dx in range(-1, 2):\n",
    "\n",
    "                        if dx != 0 and dy != 0 and i+dy >= 0 and i+dy < self.m and j+dx >= 0 and j+dx < self.n:\n",
    "                            if abs(d_noised[0][i+dy][j+dx] - d_noised[0][i][j]) <= threshold:\n",
    "                                # (x, y) format\n",
    "                                neighbours.add(((j, i), (j+dx, i+dy)))\n",
    "        adjacency_matrix = torch.zeros(\n",
    "            (self.m*self.n, self.m*self.n), dtype=bool)\n",
    "        # print(adjacency_matrix.shape)\n",
    "\n",
    "        for val in neighbours:\n",
    "            N1, N2 = val  # in (x, y) form\n",
    "            N1_x, N1_y = N1\n",
    "            N2_x, N2_y = N2\n",
    "\n",
    "            l1 = labels[(N1_x, N1_y)]\n",
    "            l2 = labels[(N2_x, N2_y)]\n",
    "\n",
    "            # Symmetric connections\n",
    "            adjacency_matrix[l1, l2] = 1\n",
    "            adjacency_matrix[l2, l1] = 1\n",
    "\n",
    "        return adjacency_matrix\n",
    "\n",
    "\n",
    "class GraphDropout(nn.Module):\n",
    "    def __init__(self, p=0.5) -> None:\n",
    "        super(GraphDropout, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, adjacency_matrix):\n",
    "        if self.train:\n",
    "            mask = torch.empty_like(adjacency_matrix).bernoulli_(1 - self.p)\n",
    "            output = adjacency_matrix * mask\n",
    "\n",
    "        else:\n",
    "            output = adjacency_matrix\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractGraph(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(ExtractGraph, self).__init__()\n",
    "\n",
    "        self.maxpool = MaxPool(pool_size=2)\n",
    "        self.noise = Noise(R_scale=0.4)  # From paper results\n",
    "        self.dropout = GraphDropout(p=0.5)\n",
    "\n",
    "    def forward(self, d_coarse, R_scale):\n",
    "\n",
    "        # print('d_coarse: ', d_coarse.shape, 'type: ', d_coarse.dtype)\n",
    "        d_pool = self.maxpool.forward(d_coarse)\n",
    "        m = d_pool.shape[1]\n",
    "        n = d_pool.shape[2]\n",
    "        self.interval_threshold = IntervalThreshold(m, n)\n",
    "        self.recon_graph = ReconGraph(m, n)\n",
    "\n",
    "        # print(\"pooled shape \", d_pool.shape)\n",
    "        d_noise = self.noise.forward(d_pool)\n",
    "        threshold = self.interval_threshold.forward(d_pool)\n",
    "        adjacency_matrix = self.recon_graph.forward(d_noise, threshold)\n",
    "        adjacency_matrix = self.dropout.forward(adjacency_matrix)\n",
    "\n",
    "        return adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        encoder = models.resnet.resnet50(\n",
    "            weights=models.ResNet50_Weights.DEFAULT)\n",
    "        encoder = nn.Sequential(*list(encoder.children()))[:3]\n",
    "        self.resnet_encoder = encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.resnet_encoder.eval()\n",
    "        return self.resnet_encoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "preprocessing_transform_2 = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_depth_dataloader import GCNDepthDataLoader\n",
    "\n",
    "# for train set\n",
    "nyu_dataset_train = GCNDepthDataLoader(mode='train',\n",
    "                                       image_folder='../dataset/dataset/nyu_depth_v2/official_splits/train/rgb',\n",
    "                                       depth_folder='../dataset/dataset/nyu_depth_v2/official_splits/train/depth',\n",
    "                                       transform=preprocessing_transform_2)\n",
    "\n",
    "nyu_dataset_test = GCNDepthDataLoader(mode='test',\n",
    "                                      image_folder='../dataset/dataset/nyu_depth_v2/official_splits/test/rgb',\n",
    "                                      depth_folder='../dataset/dataset/nyu_depth_v2/official_splits/test/depth',\n",
    "                                      transform=preprocessing_transform_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adityadandwate/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adityadandwate/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /Users/adityadandwate/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "midas_model_type = \"MiDaS_small\"\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", midas_model_type)\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if midas_model_type == \"DPT_Large\" or midas_model_type == \"DPT_Hybrid\":\n",
    "    midas_transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    midas_transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GraphDataLoader(Dataset):\n",
    "    def __init__(self, dataset, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rgb, true_depth = self.dataset.__getitem__(index)\n",
    "        features, adj_matrix, true_adj_matrix = self.graph_extract(\n",
    "            rgb, true_depth)\n",
    "        print('working')\n",
    "        return features, adj_matrix, true_adj_matrix, true_depth\n",
    "\n",
    "    def graph_extract(self, rgb, true_depth):\n",
    "        extractor = ExtractGraph()\n",
    "        encoder = Encoder()\n",
    "\n",
    "        rgb = rgb.permute(1, 2, 0)*255\n",
    "        rgb = rgb.numpy()\n",
    "        # print('rgb shape ', rgb.shape, ' true depth shape ', true_depth.shape)\n",
    "        rgb = midas_transform(rgb).to(device)  # (1, C, H, W)\n",
    "\n",
    "        # print('rgb shape after midas transform ', rgb.shape)\n",
    "        with torch.no_grad():\n",
    "            depth_map = midas(rgb)  # (C, H, W) where C = 1\n",
    "            down_rgb = encoder.forward(rgb)\n",
    "\n",
    "        # print('midas depth shape: ',depth_map.shape, ' encoded shape: ', down_rgb.shape)\n",
    "        target_size = down_rgb.shape[2:]\n",
    "        num_downsampled_channels = down_rgb.shape[1]\n",
    "        # Maxpool will downsample by half further\n",
    "        target_size = [x*2 for x in target_size]\n",
    "        # print('targetsize: ', target_size)\n",
    "        resize_transform = transforms.Resize(target_size)\n",
    "        depth_map = depth_map\n",
    "        # Downsample midas output to (192, 256) using bilinear interpolation\n",
    "        depth_map = resize_transform(depth_map)\n",
    "\n",
    "        true_depth_map = resize_transform(true_depth)\n",
    "        true_depth_map = true_depth_map.to(device=device).to(torch.float32)\n",
    "\n",
    "        # print(\"true depth shape \", true_depth_map.shape, \" depth map shape \", depth_map.shape)\n",
    "        adjacency_matrix = extractor.forward(depth_map, 0.4)\n",
    "        true_adjacency_matrix = extractor.forward(true_depth_map, 0.4)\n",
    "        # print('pred mat shape: ', adjacency_matrix.shape)\n",
    "        # print('true mat shape: ', true_adjacency_matrix.shape)\n",
    "\n",
    "        # shape will be (64, 120*160)\n",
    "        node_features = torch.reshape(down_rgb, (num_downsampled_channels, -1))\n",
    "        node_features = node_features.t() # transpose to shape (N, D)\n",
    "\n",
    "        return node_features, adjacency_matrix, true_adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyu_dataset_processes_train = GraphDataLoader(\n",
    "    nyu_dataset_train, transform=preprocessing_transform_2)\n",
    "nyu_dataset_processes_test = GraphDataLoader(\n",
    "    nyu_dataset_test, transform=preprocessing_transform_2)\n",
    "\n",
    "processed_train_dataloader = DataLoader(nyu_dataset_processes_train, batch_size=32, shuffle=True)\n",
    "processed_test_dataloader = DataLoader(nyu_dataset_processes_test, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_edgeindex(matrix):\n",
    "\n",
    "    # print(features.shape)\n",
    "\n",
    "    batch_size, num_nodes, _ = matrix.size()\n",
    "    print('num of nodes ', num_nodes)\n",
    "    edge_indices = []\n",
    "    num_nodes = [num_nodes for i in range(batch_size)]\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        adj = matrix[i]\n",
    "        adj_coo = adj.to_sparse().coalesce()\n",
    "        edge_index = adj_coo.indices()\n",
    "        edge_indices.append(edge_index)\n",
    "        \n",
    "    # graph_data = [pyg_Data(edge_index=e, x=x)\n",
    "    #               for e, x in zip(edge_indices, features)]\n",
    "\n",
    "    return edge_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset as pyg_Dataset, download_url\n",
    "from torch_geometric.data import Data as pyg_Data\n",
    "from torch_geometric.data import Batch as pyg_Batch\n",
    "from torch_geometric.loader import DataLoader as pyg_Loader\n",
    "from pathlib import Path \n",
    "from tqdm import tqdm\n",
    "\n",
    "class GraphDataset(pyg_Dataset):\n",
    "\n",
    "    def __init__(self, root = None, transform = None, pre_transform = None, pre_filter = None, log: bool = True):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter, log)\n",
    "        self.data_list = []\n",
    "        # self.intermed_edge_indices = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.pre_transform = pre_transform\n",
    "        self.pre_filter = pre_filter\n",
    "        self.log = log\n",
    "        print(self.processed_dir)\n",
    "        # self.true_edge_indices = []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" List all pytorch files available in the root directory.\n",
    "        A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "        Those files are created by the process functions and are graph that can be used for training and evaluation.\n",
    "        \"\"\"\n",
    "        return [str(p.with_suffix(\".pt\").name) for p in Path(self.root).glob(\"*.vtk\")]\n",
    "\n",
    "    def process(self):\n",
    "        \n",
    "        print(self.processed_dir)\n",
    "        idx = 0\n",
    "        \n",
    "        for img_batch in tqdm(processed_train_dataloader):\n",
    "            feature, intermed_adj_matrix, true_adj_matrix, true_depth = img_batch # batch dim is 32\n",
    "\n",
    "            # Feature shape should be (N, D) check if it in fact of that shape\n",
    "            true_edge_indices, intermed_edge_indices =self.convert_to_edgeindex(intermed_adj_matrix, true_adj_matrix)\n",
    "\n",
    "            for i in range(len(true_edge_indices)):\n",
    "                true_edge_index = true_edge_indices[i]\n",
    "                intermed_edge_index = intermed_edge_indices[i]\n",
    "\n",
    "                file_save_path = Path(self.processed_dir) / f\"{idx}.pt\"\n",
    "\n",
    "                x = feature[i]\n",
    "                true_d = true_depth[i]\n",
    "\n",
    "                data = pyg_Data(\n",
    "                    x=x,\n",
    "                    edge_index=intermed_edge_index,\n",
    "                    true_depth = true_d,\n",
    "                    true_edge_index = true_edge_index\n",
    "                )\n",
    "\n",
    "                torch.save(data, file_save_path)\n",
    "                idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(Path(self.processed_dir) / f'{idx}.pt')\n",
    "        return data\n",
    "\n",
    "    def convert_to_edgeindex(self, intermed_matrix, true_matrix):\n",
    "\n",
    "        # print(features.shape)\n",
    "        batch_size, num_nodes, _ = intermed_matrix.size()\n",
    "        true_edge_indices = []\n",
    "        intermed_edge_indices = []\n",
    "        num_nodes = [num_nodes for i in range(batch_size)]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            intermed_adj = intermed_matrix[i]\n",
    "            intermed_adj_coo = intermed_adj.to_sparse().coalesce()\n",
    "            intermed_edge_index = intermed_adj_coo.indices()\n",
    "\n",
    "            true_adj = true_matrix[i]\n",
    "            true_adj_coo = true_adj.to_sparse().coalesce()\n",
    "            true_edge_index = true_adj_coo.indices()\n",
    "\n",
    "            true_edge_indices.append(true_edge_index)\n",
    "            intermed_edge_indices.append(intermed_edge_index)\n",
    "\n",
    "        return true_edge_indices, intermed_edge_indices\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/graphs/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000012?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m GraphDataset(root \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m../dataset/graphs/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 12'\u001b[0m in \u001b[0;36mGraphDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, transform \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, pre_transform \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, pre_filter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=10'>11</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=11'>12</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=12'>13</a>\u001b[0m     \u001b[39m# self.intermed_edge_indices = []\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:57\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch_geometric/data/dataset.py:97\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_process:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch_geometric/data/dataset.py:230\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    229\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 230\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    232\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 12'\u001b[0m in \u001b[0;36mGraphDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=32'>33</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_batch \u001b[39min\u001b[39;00m tqdm(processed_train_dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=35'>36</a>\u001b[0m     feature, intermed_adj_matrix, true_adj_matrix, true_depth \u001b[39m=\u001b[39m img_batch \u001b[39m# batch dim is 32\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000010?line=37'>38</a>\u001b[0m     \u001b[39m# Feature shape should be (N, D) check if it in fact of that shape\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 9'\u001b[0m in \u001b[0;36mGraphDataLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=13'>14</a>\u001b[0m     rgb, true_depth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(index)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=14'>15</a>\u001b[0m     features, adj_matrix, true_adj_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_extract(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=15'>16</a>\u001b[0m         rgb, true_depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mworking\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m features, adj_matrix, true_adj_matrix, true_depth\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 9'\u001b[0m in \u001b[0;36mGraphDataLoader.graph_extract\u001b[0;34m(self, rgb, true_depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=47'>48</a>\u001b[0m \u001b[39m# print(\"true depth shape \", true_depth_map.shape, \" depth map shape \", depth_map.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=48'>49</a>\u001b[0m adjacency_matrix \u001b[39m=\u001b[39m extractor\u001b[39m.\u001b[39mforward(depth_map, \u001b[39m0.4\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=49'>50</a>\u001b[0m true_adjacency_matrix \u001b[39m=\u001b[39m extractor\u001b[39m.\u001b[39;49mforward(true_depth_map, \u001b[39m0.4\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=50'>51</a>\u001b[0m \u001b[39m# print('pred mat shape: ', adjacency_matrix.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=51'>52</a>\u001b[0m \u001b[39m# print('true mat shape: ', true_adjacency_matrix.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=52'>53</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=53'>54</a>\u001b[0m \u001b[39m# shape will be (64, 120*160)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000007?line=54'>55</a>\u001b[0m node_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(down_rgb, (num_downsampled_channels, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 3'\u001b[0m in \u001b[0;36mExtractGraph.forward\u001b[0;34m(self, d_coarse, R_scale)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000002?line=19'>20</a>\u001b[0m d_noise \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise\u001b[39m.\u001b[39mforward(d_pool)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000002?line=20'>21</a>\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterval_threshold\u001b[39m.\u001b[39mforward(d_pool)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000002?line=21'>22</a>\u001b[0m adjacency_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecon_graph\u001b[39m.\u001b[39;49mforward(d_noise, threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000002?line=22'>23</a>\u001b[0m adjacency_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout\u001b[39m.\u001b[39mforward(adjacency_matrix)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000002?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m adjacency_matrix\n",
      "\u001b[1;32m/Users/adityadandwate/Desktop/IIIT-H Internship/scripts/graph_dataset.ipynb Cell 2'\u001b[0m in \u001b[0;36mReconGraph.forward\u001b[0;34m(self, d_noised, threshold)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=51'>52</a>\u001b[0m             \u001b[39mfor\u001b[39;00m dx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=53'>54</a>\u001b[0m                 \u001b[39mif\u001b[39;00m dx \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m dy \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m+\u001b[39mdy \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m+\u001b[39mdy \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39mand\u001b[39;00m j\u001b[39m+\u001b[39mdx \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m j\u001b[39m+\u001b[39mdx \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=54'>55</a>\u001b[0m                     \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39;49m(d_noised[\u001b[39m0\u001b[39;49m][i\u001b[39m+\u001b[39;49mdy][j\u001b[39m+\u001b[39;49mdx] \u001b[39m-\u001b[39;49m d_noised[\u001b[39m0\u001b[39;49m][i][j]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m threshold:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=55'>56</a>\u001b[0m                         \u001b[39m# (x, y) format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=56'>57</a>\u001b[0m                         neighbours\u001b[39m.\u001b[39madd(((j, i), (j\u001b[39m+\u001b[39mdx, i\u001b[39m+\u001b[39mdy)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=57'>58</a>\u001b[0m adjacency_matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityadandwate/Desktop/IIIT-H%20Internship/scripts/graph_dataset.ipynb#ch0000001?line=58'>59</a>\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = GraphDataset(root = '../dataset/graphs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth depth is of shape (1, 480, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12288, 64], edge_index=[2, 15899], true_depth=[1, 480, 640], true_edge_index=[2, 18372])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inst = torch.load('../dataset/graphs/processed/0.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16b550fe05c3b71bbf0c7afa52a3ee78d653553480e3fe9ba3d485dd7a41f4b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
